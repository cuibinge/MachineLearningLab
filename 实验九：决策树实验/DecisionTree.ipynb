{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验九：决策树\n",
    "### 概述\n",
    "&ensp;&ensp; 本实验中使用两个不同的数据集分别来测试决策树回归问题的CART算法和决策树分类问题的CART算法。\n",
    "### 实验环境\n",
    "+ Ubuntu\n",
    "+ Jupyter NoteBook\n",
    "\n",
    "### 实验目标\n",
    "\n",
    "   完成本实验后，您能够：\n",
    "1. 掌握如何使用CART对决策树分类算法进行优化\n",
    "2. 掌握如何使用CART对决策树回归算法进行优化\n",
    "3. 掌握如何将标签转为向量形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务1：决策树CART算法基类\n",
    "#### 【任务目标】\n",
    "&ensp;&ensp;实现决策树CART算法基类\n",
    "#### 【任务步骤】\n",
    "1. 定义决策树节点数据结构\n",
    "2. 实现决策树CART算法基类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义决策树节点数据结构\n",
    "class Node:\n",
    "    j = None\n",
    "    theta = None\n",
    "    p = None\n",
    "    left = None\n",
    "    right = None\n",
    "\n",
    "\"\"\"\n",
    "类说明：DecisionTreeBase\n",
    "    编写代码实现决策树CART算法的基类\n",
    "    \n",
    "Parameters:\n",
    "        max_depth         - 决策树深度\n",
    "    feature_sample_rate   - 选取特征的比例\n",
    "        get_score         - 分值函数指针\n",
    "Returns:\n",
    "\"\"\"\n",
    "class DecisionTreeBase:\n",
    "    def __init__(self, max_depth, feature_sample_rate, get_score):\n",
    "        self.max_depth = max_depth\n",
    "        self.feature_sample_rate = feature_sample_rate\n",
    "        self.get_score = get_score\n",
    "  \n",
    "    # 将数据按照特征j的取值是否大于阈值theta分成两部分\n",
    "    def split_data(self, j, theta, X, idx):\n",
    "#####  Start Code Here  #####  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 按照比例选取特征组\n",
    "    def get_random_features(self, n):\n",
    "\n",
    "    \n",
    "    \n",
    "    # 采用贪心策略来寻找最优数据划分\n",
    "    def find_best_split(self, X, y, idx):\n",
    "        # 获取X的维度\n",
    "       \n",
    "        \n",
    "        # 初始化参数\n",
    "\n",
    "        \n",
    "        # 调用get_random_features函数随机选取一组特征\n",
    "       \n",
    "        \n",
    "        # 遍历选择的特征\n",
    "        for j in selected_j:\n",
    "            \n",
    "            # 计算特征j的不同取值，作为备选的阈值theta\n",
    "            \n",
    "            \n",
    "            # 遍历所有的theta\n",
    "            for theta in thetas:\n",
    "                \n",
    "                # 将数据按照特征j的取值是否大于阈值theta分成两部分 \n",
    "               \n",
    "                \n",
    "                # 确保划分的两部分都不是空集\n",
    "               \n",
    "                \n",
    "                # 对每一部分数据计算其分值\n",
    "                \n",
    "                \n",
    "                # 计算两部分分值的加权和\n",
    "               \n",
    "                \n",
    "                # 更新参数\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_j = j\n",
    "                    best_theta = theta\n",
    "                    best_idx1 = idx1\n",
    "                    best_idx2 = idx2\n",
    "                    \n",
    "        return best_j, best_theta, best_idx1, best_idx2, best_score\n",
    "    \n",
    "    # 生成一颗深度不超过max_depth的树\n",
    "    def generate_tree(self, X, y, idx, d):\n",
    "        # 生成根节点\n",
    "        \n",
    "        \n",
    "        # 判断深度是否等于0或者是否只有1条训练数据\n",
    "       \n",
    "        \n",
    "        # 计算不做数据划分时得到的目标函数值\n",
    "       \n",
    "        \n",
    "        # 寻找最优数据划分\n",
    "        \n",
    "        \n",
    "        # 判断划分数据是否带来益处，如果有则记录这一划分信息\n",
    "        \n",
    "        \n",
    "#####  End Code Here  #####    \n",
    "        # 递归生成当前节点的左节点与右节点\n",
    "        r.left = self.generate_tree(X, y, idx1, d - 1)\n",
    "        r.right = self.generate_tree(X, y, idx2, d - 1)\n",
    "        return r\n",
    "    \n",
    "    # CART算法入口\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.generate_tree(X, y, range(len(X)), self.max_depth)\n",
    "    \n",
    "    def get_prediction(self, r, x):\n",
    "        if r.left == None and r.right == None:\n",
    "            return r.p\n",
    "        value = x[r.j]\n",
    "        if value <= r.theta:\n",
    "            return self.get_prediction(r.left, x)\n",
    "        else:\n",
    "            return self.get_prediction(r.right, x)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = list()\n",
    "        for i in range(len(X)):\n",
    "            y.append(self.get_prediction(self.root, X[i]))\n",
    "        return np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务2：决策树回归问题和分类问题的CART算法\n",
    "#### 【任务目标】\n",
    "&ensp;&ensp;实现决策树回归问题和分类问题的CART算法\n",
    "#### 【任务步骤】\n",
    "1. 实现方差的计算\n",
    "2. 实现熵的定义\n",
    "3. 实现决策树回归问题和分类问题的CART算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算方差\n",
    "def get_var(y, idx):\n",
    "    y_avg = np.average(y[idx]) * np.ones(len(idx))\n",
    "    return np.linalg.norm(y_avg - y[idx], 2) ** 2 / len(idx)\n",
    "\n",
    "# 继承决策树基类\n",
    "class DecisionTreeRegressor(DecisionTreeBase):\n",
    "    \n",
    "    \n",
    "    \n",
    "# 熵的定义\n",
    "def get_entropy(y, idx):\n",
    "    _, k = y.shape\n",
    "    p = np.average(y[idx], axis = 0)\n",
    "    return - np.log(p + 0.001 * np.random.rand(k)).dot(p.T)\n",
    "\n",
    "# 继承决策树基类\n",
    "class DecisionTreeClassifier(DecisionTreeBase):\n",
    "\n",
    "    \n",
    "        \n",
    "    # 完成概率预测任务\n",
    "    def predict_proba(self, X):\n",
    "       \n",
    "    \n",
    "    \n",
    "    # 将概率预测结果转为类别预测\n",
    "    def predict(self, X):\n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务3：共享单车问题\n",
    "#### 【数据集介绍】\n",
    "&ensp;&ensp;共享单车系统为人们的出行提供了极大的便利。人们可以从一个地点租车，并于另一\n",
    "地点还车。一个共享单车系统每天都会产生大量的租车数据。数据中包括出行时间、出发\n",
    "地、目的地等信息。共享单车问题的任务是根据租车数据预测每个共享单车服务点的单车\n",
    "需求量，从而提前准备需储备的单车数量。\n",
    "在这个问题中，每一条数据有8个特征：钟点(hour)、季节(season)、是否为节假日\n",
    "(holiday)、是否为周末(wkday)、天气状况(weather)、气温(temp)、湿度(hum)和风速\n",
    "(wdspd)。数据的标签是单车的需求量(count)。\n",
    "#### 【任务目标】\n",
    "&ensp;&ensp;训练一颗深度不超过2的决策树，并用来预测单车需求量。\n",
    "#### 【任务步骤】\n",
    "1. 加载共享单车数据集\n",
    "2. 按照一定比例划分训练集和测试集\n",
    "3. 定义模型进行训练\n",
    "4. 计算 r2 系数并输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据\n",
    "def get_data():\n",
    "    df = pd.read_csv(\"./bike.csv\")\n",
    "    df.datetime = df.datetime.apply(pd.to_datetime)\n",
    "    df['hour'] = df.datetime.apply(lambda x: x.hour)\n",
    "    y = df['count'].values\n",
    "    df.drop(['datetime', 'casual', 'registered', 'count'], 1, inplace = True)\n",
    "    X = df.values\n",
    "    return X, y\n",
    "\n",
    "# 获取共享单车数据集\n",
    "\n",
    "\n",
    "# 划分训练集和测试集 训练集：测试集 = 1:1\n",
    "\n",
    "\n",
    "# 定义决策树回归模型\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "\n",
    "\n",
    "# 预测\n",
    "\n",
    "\n",
    "print(\"tree r2 = {}\".format(r2_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务4：语音识别问题\n",
    "#### 【数据集介绍】\n",
    "&ensp;&ensp;语音识别是机器学习的重要应用场景。本例考察一个简单的语音识别问题：根据一段\n",
    "语音的特征，判断发声者的性别。在这个问题中，每条训练数据含有21个刻画声音特点的\n",
    "变量，例如音域(IQR)、音频(meanfun)、熵谱(sp.ent)等。数据还含有一个性别标签，表示\n",
    "声音来自男性还是女性。\n",
    "#### 【任务目标】\n",
    "&ensp;&ensp;训练一颗深度为5的决策树来推断发声者的性别\n",
    "#### 【任务步骤】\n",
    "1. 加载数据集\n",
    "2. 按照一定比例划分训练集和测试集\n",
    "3. 将标签转为向量形式\n",
    "4. 定义模型进行训练 \n",
    "5. 计算准确率并输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据\n",
    "def get_data():\n",
    "    df = pd.read_csv(\"./voice.csv\")\n",
    "    y = (df[\"label\"].values == \"male\").astype(np.int)\n",
    "    df.drop(['label'], 1, inplace = True)\n",
    "    X = df.values\n",
    "    return X, y.reshape(-1,1)\n",
    "\n",
    "# 获取数据\n",
    "\n",
    "\n",
    "# 划分训练集和测试集 训练集：测试集 = 1:1\n",
    "\n",
    "\n",
    "# 定义决策树分类模型\n",
    "\n",
    "\n",
    "# 运用OneHotEncoder将标签转化为向量形式\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "\n",
    "\n",
    "# 预测\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"accuracy = {}\".format(accuracy))\n",
    "print(\"precision = {}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
